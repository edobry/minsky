# Context Pollution Analysis: Critical Need for Context-Aware Tool Management

## Executive Summary

Analysis of the `minsky context generate` command reveals **critical context pollution** that makes mt#256 (Context-Aware Tool Management System) an **immediate priority** rather than a future enhancement.

**Key Finding**: Tool schemas consume **73% of total context** (15,946 out of 21,853 tokens) with **zero intelligent filtering**, representing a massive optimization opportunity.

## Problem Statement

### Current State Analysis

**Command**: `minsky context generate --analyze-only`

```
ğŸ” Context Analysis
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Model: gpt-4o
Interface Mode: cli
Tokenizer: tiktoken (cl100k_base)
Context Window: 128,000 tokens
Generated: 8/27/2025, 7:18:29 PM

Total Tokens: 21,853
Total Components: 13
Context Window Utilization: 17.1%
Largest Component: tool-schemas

ğŸ“Š Component Breakdown
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
tool-schemas           15,946 tokens (73.0%)
workspace-rules         1,009 tokens (4.6%)
tool-calling-rules        569 tokens (2.6%)
maximize-parallel-tool-calls      385 tokens (1.8%)
system-instructions       320 tokens (1.5%)
making-code-changes       247 tokens (1.1%)
maximize-context-understanding      245 tokens (1.1%)
task-management           146 tokens (0.7%)
code-citation-format      134 tokens (0.6%)
session-context           116 tokens (0.5%)
project-context            74 tokens (0.3%)
environment                52 tokens (0.2%)
communication              46 tokens (0.2%)

ğŸ’¡ Optimization Suggestions
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”½ tool-schemas
   Component "tool-schemas" dominates your context (15,946 tokens, 73.0%).
   Consider reducing its scope, splitting it into smaller components, or using only essential parts.
   Potential savings: 6,378 tokens
```

### Critical Issues Identified

1. **Massive Tool Pollution**: 15,946 tokens (73% of context) dedicated to tool schemas
2. **No Query Awareness**: System includes ALL tools regardless of user intent
3. **Category Explosion**: All 9 command categories included automatically
4. **Zero Filtering**: No mechanism to exclude irrelevant tools

### User Query Scenarios

**Test Case 1**: Debugging Query

```bash
minsky context generate --prompt "help me debug a failing test"
```

**Expected Tools**: tasks, git bisect, test runners, debugging utilities
**Actual Result**: ALL 50+ tools including session creation, config management, AI models, deployment

**Test Case 2**: Code Review Query

```bash
minsky context generate --prompt "review this pull request"
```

**Expected Tools**: git commands, diff analysis, code review tools
**Actual Result**: ALL 50+ tools including test runners, database operations, session management

**Test Case 3**: Implementation Query

```bash
minsky context generate --prompt "implement user authentication"
```

**Expected Tools**: task management, file operations, security-related tools
**Actual Result**: ALL 50+ tools including git bisect, database migration, deployment scripts

## Impact Assessment

### Token Waste Analysis

- **Current Tool Schemas**: 15,946 tokens (73.0% of total context)
- **Estimated Relevant Tools per Query**: ~15-20 tools
- **Potential Reduction**: 60-70% of tool schema tokens
- **Token Savings**: 10,000+ tokens freed for relevant content

### Context Efficiency Metrics

| Metric               | Current | Target  | Improvement              |
| -------------------- | ------- | ------- | ------------------------ |
| Tool Schema Tokens   | 15,946  | ~5,000  | 68% reduction            |
| Total Context Tokens | 21,853  | ~11,000 | 50% reduction            |
| Context Window Usage | 17.1%   | 8.6%    | 50% more efficient       |
| Relevant Tool Ratio  | ~30%    | ~90%    | 3x relevance improvement |

## Root Cause Analysis

### Code Investigation

**File**: `src/domain/context/components/tool-schemas.ts`

**Current Implementation** (Lines 104-148):

```typescript
const categories = [
  CommandCategory.TASKS,     // All task commands
  CommandCategory.SESSION,   // All session commands
  CommandCategory.SESSIONDB, // All database commands
  CommandCategory.RULES,     // All rule commands
  CommandCategory.GIT,       // All git commands
  CommandCategory.CONFIG,    // All config commands
  CommandCategory.DEBUG,     // All debug commands
  CommandCategory.INIT,      // All init commands
  CommandCategory.AI,        // All AI commands
];

for (const category of categories) {
  const commands = registry.getCommandsByCategory(category);
  for (const cmd of commands) {
    // Include EVERY command from EVERY category
    toolSchemas[cmd.id] = { ... };
  }
}
```

**Issue**: No filtering logic based on user context, query, or relevance.

### Missing Capabilities

1. **No Query Analysis**: User prompts are completely ignored
2. **No Semantic Matching**: No embedding-based tool relevance
3. **No Category Filtering**: All categories included regardless of context
4. **No Context Awareness**: Session/task context not considered
5. **No Configuration**: No way to limit tool count or set relevance thresholds

## Solution Requirements

### Immediate Priority Features

1. **Query-Aware Filtering**: Parse user prompts to determine relevant tools
2. **Semantic Tool Matching**: Use embeddings to find contextually relevant tools
3. **Category Selection**: Include only relevant command categories
4. **Token Budget Management**: Enforce limits on tool schema size
5. **Backward Compatibility**: Maintain existing behavior when no query provided

### Infrastructure Dependencies

**Available Infrastructure** (Ready for Use):

- âœ… PostgreSQL + pgvector database storage (mt#253)
- âœ… OpenAI embedding service integration (mt#445)
- âœ… Similarity search with configurable thresholds
- âœ… Session database connection reuse
- ğŸš§ Generic similarity service foundation (mt#447)

### Integration Points

1. **Context Generation System**: Primary integration target
2. **Tool-Schemas Component**: Modification target for query awareness
3. **Embedding Infrastructure**: Leverage existing proven patterns
4. **MCP Server**: Future dynamic tool registration

## Success Criteria

### Quantitative Metrics

- **Tool Schema Reduction**: 60-70% token reduction when user query provided
- **Context Optimization**: Free 10,000+ tokens for relevant information
- **Performance**: Sub-second tool selection response times
- **Relevance**: 90%+ of included tools should be relevant to user query

### Qualitative Improvements

- **User Experience**: Context generation provides focused, relevant tool sets
- **AI Effectiveness**: Improved tool selection due to reduced choice overload
- **Scalability**: System handles growing tool ecosystem intelligently
- **Maintainability**: Clear configuration and easy customization

## Risk Assessment

### Technical Risks

| Risk                            | Probability | Impact | Mitigation                                     |
| ------------------------------- | ----------- | ------ | ---------------------------------------------- |
| Embedding performance issues    | Low         | Medium | Use proven patterns from mt#253/445            |
| Relevance accuracy problems     | Medium      | High   | Implement fallback to category-based filtering |
| Backward compatibility breaking | Low         | High   | Maintain existing behavior when no query       |
| Integration complexity          | Medium      | Medium | Build on existing infrastructure               |

### Delivery Risks

| Risk                        | Probability | Impact | Mitigation                            |
| --------------------------- | ----------- | ------ | ------------------------------------- |
| Infrastructure dependencies | Low         | Medium | All required infrastructure available |
| Testing complexity          | Medium      | Low    | Use existing embedding test patterns  |
| Performance degradation     | Low         | High   | Implement caching and optimization    |

## Recommendations

### Implementation Priority

**CRITICAL**: This issue should be elevated to **immediate priority** because:

1. **Massive Impact**: 73% context waste affects every AI interaction
2. **Proven Infrastructure**: All required components are available
3. **Clear Solution Path**: Existing patterns from tasks/rules can be reused
4. **User Value**: Immediate improvement in context generation quality

### Next Steps

1. **Week 1**: Implement tool embeddings infrastructure using proven patterns
2. **Week 2**: Integrate with generic similarity service for tool selection
3. **Week 3**: Modify tool-schemas component for query-aware filtering
4. **Week 4**: Test, validate, and optimize implementation

### Success Validation

**Before/After Test Protocol**:

```bash
# Test various user queries and measure:
# 1. Token reduction in tool-schemas component
# 2. Relevance of included tools to user query
# 3. Performance of tool selection
# 4. Overall context generation quality

minsky context generate --prompt "debug test failure" --analyze
minsky context generate --prompt "review pull request" --analyze
minsky context generate --prompt "implement authentication" --analyze
```

## Conclusion

The context pollution problem represents a **critical optimization opportunity** that can:

- **Reduce context usage by 50%** (21,853 â†’ 11,000 tokens)
- **Free 10,000+ tokens** for more relevant information
- **Improve AI tool selection** through focused, relevant tool sets
- **Scale intelligently** as the tool ecosystem grows

This analysis strongly supports elevating mt#256 to **critical priority** with immediate implementation using the proven embedding infrastructure from mt#253, mt#445, and the emerging generic similarity service from mt#447.
