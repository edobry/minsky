---
description: Use for test execution requirements and verification protocols. Apply after implementing tests per testing-boundaries
globs:
alwaysApply: false
---
# Test Execution and Verification

## Integration with Testing Rule System
- This rule is part of the Minsky testing rule system. Start with [testing-router](mdc:.cursor/rules/testing-router.mdc) for the complete overview.
- This rule focuses on **when to run tests** and **verification protocols**, complementing other testing rules.

## Test Execution Requirements

1. **When to Run Tests**
   - Run tests after ANY change to:
     - Source code files (*.ts, *.js)
     - Test files (*.test.ts, *.spec.ts)
     - Configuration files that affect test behavior
   - Do NOT run tests for:
     - Documentation changes (*.md)
     - Comment-only changes
     - Formatting-only changes (unless they affect test output)

2. **Which Tests to Run**
   - Run all tests in the affected package/module
   - For changes to shared utilities or core functionality, run all tests
   - Use `bun test` for the default test suite
   - Use `bun test --coverage` when making significant changes
   - Use `bun lint:tests` to scan for placeholder tests

3. **Test Success Criteria**
   - All tests must pass (no failures)
   - No new test warnings should be introduced
   - Test coverage should not decrease for modified files
   - Flaky tests should be fixed or marked as such
   - `bun lint:tests` must pass with exit code 0 (no placeholder tests)

## Verification Protocols

### Batch Verification
- After each set of related changes, run all of these checks:
  ```bash
  bun lint        # Check code quality
  bun type-check  # Verify TypeScript types
  bun test        # Run tests
  bun lint:tests  # Check for placeholder tests
  ```

### Verification Checkpoints
- Verification MUST be performed:
  - Before committing changes
  - Before opening a pull request
  - Before marking a task as complete
  - After resolving merge conflicts
  - After refactoring shared code

### Test Pass/Fail Gating
- Failed tests MUST block further progress
- You MUST NOT commit, merge, or ship code with failing tests
- Broken tests MUST be fixed rather than skipped or removed
- If test failures are expected due to implementation changes, update tests FIRST

## Core Principles
1. **Zero Tolerance for Placeholder Tests**: All tests must meaningfully test actual functionality.
2. **Test-First Development**: Write tests before implementing features and fixes.
3. **Isolate Test Dependencies**: Use proper mocking and test isolation techniques.
4. **Verify All Changes**: Run appropriate tests after any code change.

## Enforcing Test Quality

- All pull requests must pass the full test suite
- Use `bun lint:tests` to detect placeholder tests automatically
- Pre-commit hooks should prevent committing placeholder tests
- Code reviews should specifically check for test quality and coverage
- Periodically review test coverage and address gaps

## Correct Mocking Approaches

**IMPORTANT: Always use centralized mocking utilities from `src/utils/test-utils/mocking.ts`**

```typescript
// ❌ INCORRECT - Using platform APIs directly
const mockFn = jest.fn();
mock.module("../path/to/module", () => ({}));

// ✅ CORRECT - Using centralized utilities
import { createMock, mockModule, setupTestMocks } from "../../utils/test-utils/mocking";
setupTestMocks();
const mockFn = createMock();
mockModule("../path/to/module", () => ({}));
```

See [bun-test-patterns](mdc:.cursor/rules/bun-test-patterns.mdc) for comprehensive guidance on mocking utilities.
