
# Self-Improvement

When the user indicates that your actions, reasoning, or responses are incorrect or suboptimal, or when they express preferences for future behavior, implement this systematic error detection and correction framework.

## CLI Command Output Design

For detailed CLI output design principles, see [cli-output-design](mdc:.cursor/rules/cli-output-design.mdc).

## Error Detection Signals

### User Dissatisfaction Signals

- Direct correction: "that's wrong", "incorrect", "not right"
- Questions about rationale: "why did you do that?", "what were you thinking?"
- Expressions of frustration: "you're doing [problem] again", "you keep making this mistake"
- Implied dissatisfaction: "that's not what I asked for", "this doesn't work"
- Preference directives: "make sure to always...", "going forward, always..."

## Self-Reflection Protocol

**When triggered, follow this exact procedure:**

1. **Stop Current Task** - Immediately pause and acknowledge feedback
2. **Root Cause Analysis** - Identify specific failure cause and error category:
   ```
   [ ] Assumption Error: Started with incorrect premise
   [ ] Process Error: Used wrong methodology/approach
   [ ] Instruction Error: Misunderstood or skipped requirements
   [ ] Context Error: Failed to consider relevant information
   [ ] Pattern Error: Applied pattern inappropriately
   [ ] Verification Error: Failed to validate before proceeding
   [ ] Tool Error: Misused available tools/functions
   [ ] Preference Error: Failed to adhere to user preferences
   [ ] Completion Assessment Error: Declared completion without proper verification
   ```
3. **Verbalize Understanding** - Confirm comprehension of user's concern
4. **Apply Correction** - Make immediate changes using tools, not plans
5. **Verify Alignment** - Confirm approach meets user needs before resuming

## Rule Update Authority Hierarchy

When updating rules based on feedback:

1. **Project Workflow/Process Rules**: Update first for process/workflow requirements
2. **User-Preferences Rule**: Update for personal preferences not covered by workflow rules
3. **Self-Improvement Rule**: Update for meta-process corrections and error analysis
4. **Domain-Specific Rules**: Update only for domain-specific issues

**CRITICAL**: After identifying required rule changes, they MUST be implemented immediately using edit tools, not merely described.

### ⚠️ DO NOT UPDATE SELF-IMPROVEMENT FOR WORKFLOW ISSUES

**WRONG**: Updating self-improvement.mdc for commit protocols, security practices, development workflows
**CORRECT**: Update appropriate workflow/process rules, then reference them from self-improvement if needed

**Self-improvement is ONLY for:**
- Meta-process corrections (how to follow rules)
- Error analysis patterns
- Rule application failures
- Process improvement methodology

**Self-improvement is NOT for:**
- Commit workflows → Update commit protocol rules
- Security practices → Update [security-protocol](mdc:.cursor/rules/security-protocol.mdc) rule
- Development processes → Update workflow rules
- Technical procedures → Update domain-specific rules

## Examples

### Error Correction

// AVOID
User: "That's not correct. I needed the absolute path."
Assistant: "I'll fix that right away." [proceeds without understanding root cause]

// PREFER
User: "That's not correct. I needed the absolute path."
Assistant: [identifies mental model failure] "I see my error. I assumed relative paths would resolve against the current directory, but they actually resolve against the workspace root. This violates the session-first-workflow rule requiring absolute paths. I should have verified my changes were applied correctly. I'll now use the absolute path and confirm the changes are applied."

### Preference Handling

// AVOID
User: "Going forward, always use absolute paths when editing files in the session workspace."
Assistant: "I'll do that." [no rule update, preference likely to be forgotten]

// PREFER
User: "Going forward, always use absolute paths when editing files in the session workspace."
Assistant: "I'm updating the session-first-workflow rule to explicitly require absolute paths for all file edits in session workspaces. I'll add a verification step to confirm file locations before edits. This will ensure consistent correct behavior." [documents change in appropriate rule]

## Rule System Organization

For rule system organization principles, see [rule-creation-guidelines](mdc:.cursor/rules/rule-creation-guidelines.mdc).

## Common Self-Improvement Scenarios

### Wrong Rule Application

If you applied an incorrect rule or missed applying a relevant rule:

```
I apologize for applying the wrong rule. I see that this situation calls for the [correct-rule] instead of [incorrect-rule]. The key difference is [explanation]. I'll now apply the correct rule.
```

### Confusing Output

If your explanation was unclear or confusing:

```
I see my explanation was confusing. Let me clarify: [simple, direct explanation]. The core point is [key takeaway]. Does that make more sense?
```

### System Limitations

If you hit a system limitation:

```
I understand what you're asking for, but I'm limited in my ability to [specific limitation]. Let me suggest an alternative approach: [workaround].
```

### User Preference Alignment

If the user expresses a preference for how something should be done:

```
I understand your preference for [specific preference]. I'll adjust my approach to [specific change] going forward. Let me demonstrate that now by [example of implementing preference].
```

## ⚠️ Critical Error Recovery Protocol

### High-Risk Operation Identification

- Before executing ANY operation that:
  1. Modifies data permanently (deletion, overwriting)
  2. Affects shared resources (remote repositories, shared branches)
  3. Uses tools with destructive capabilities (`git reset --hard`, `rm -rf`, etc.)
  4. Cannot be easily undone
  - You MUST explicitly acknowledge the operation as high-risk and follow the steps below.

### Pre-Execution Documentation

1. **State of the System**:

   - Document the current state using appropriate commands (`git status`, `ls`, etc.)
   - Save critical information (e.g., commit hashes, file listings) that would be needed for recovery
   - Create reference points (e.g., temporary branches in Git) when applicable

2. **Execution Plan**:

   - Explicitly state the exact command(s) to be executed
   - Document expected outcome in detail
   - Identify potential failure modes and their consequences
   - Document recovery options for each potential failure

3. **Safer Alternatives Analysis**:
   - Always consider and document at least one safer alternative approach
   - Compare risk profiles of different approaches
   - Justify choice of approach based on risk vs. benefit

### Post-Error Recovery Procedure

If a critical error occurs during execution:

1. **Immediate Containment**:

   - STOP all operations immediately
   - DO NOT attempt further operations that could complicate recovery
   - Document the exact state after error (evidence collection)
   - Preserve all information needed for recovery

2. **Systematic Analysis**:

   - Compare actual state to pre-execution documented state
   - Identify exactly what changed and what was lost
   - Determine if the changes can be recovered and how
   - Map out all possible recovery paths

3. **Staged Recovery**:

   - Create isolated environment for recovery when possible
   - Never attempt recovery directly on production/shared resources if avoidable
   - Execute recovery steps in stages with verification between each stage
   - Create recovery checkpoints to avoid compounding errors

4. **Prevent Recurrence**:
   - Document the error and recovery process in detail
   - Update relevant rules with specific preventative measures
   - Create verification steps that would have prevented the error
   - Add explicit warnings about the specific error scenario

### Terminal Error Response

For catastrophic errors (data loss, corruption of shared resources, security breaches):

1. **Immediate Notification**: Explicitly inform the user of the severity using "TERMINAL ERROR" language
2. **Complete Operational Pause**: Halt ALL operations until user guidance is received
3. **Full Transparency**: Provide complete details of what happened, why, and potential consequences
4. **Comprehensive Documentation**: Document exact commands that led to the error
5. **Rule System Update**: IMMEDIATELY update rules to prevent recurrence

## ⚠️ Systematic Verification Failure Protocol

**Addresses repeated failures to apply existing verification rules**

### When User Reports Repeated Rule Violations:

1. **Immediate Verification Audit**:

   - Execute all mandatory verification checks from relevant loaded rules
   - Do not submit responses without completing required scans
   - Rewrite completely if violations found

2. **Root Cause Analysis**:

   - Process Gap: Not executing mandatory steps from existing rules
   - Attention Failure: Rushing without applying required checks
   - Rule Application Failure: Having correct rules but ignoring them

3. **Enforcement Mechanism**:
   - If user reports SAME violation twice: Treat as critical protocol failure
   - Immediately audit complete verification process
   - Update enforcement mechanisms to prevent recurrence

### Mandatory Response Verification

**EVERY response must pass this check:**

1. **Rule Compliance**: Execute all mandatory protocols from relevant loaded rules
2. **Response Quality**: Answer actual question, implement rather than describe
3. **Verification Complete**: Confirm all required checks performed

## ⚠️ Critical Resource Existence Verification Protocol

**Addresses pattern where AI claims resources don't exist without proper verification**

### Documented Verification Failures

**Pattern: Resource Existence Claims Without Verification**
- **Error**: Claiming files, rules, or resources don't exist without using search tools
- **User Signal**: "yes there is @self-improvement.mdc" (after AI claimed it didn't exist)
- **Root Cause**: Verification Error - failed to use proper search tools before making negative claims
- **Correct Approach**: ALWAYS use file_search and grep_search before claiming non-existence

### Mandatory Verification Protocol

**BEFORE claiming ANY resource doesn't exist, MUST complete:**

1. **File Search**: Use `file_search` tool to look for the resource by name
2. **Content Search**: Use `grep_search` if needed for content-based verification
3. **Exhaustive Search**: Only claim non-existence after comprehensive search
4. **Documentation**: Document search attempts in response

### Examples

// AVOID
```
User: "what @self-improvement.mdc"
Assistant: "It looks like there isn't a rule called `self-improvement.mdc` available"
```

// PREFER
```
User: "what @self-improvement.mdc"
Assistant: [uses file_search tool first] "I found the self-improvement.mdc rule at..."
```

### Enforcement Mechanism

- **First Violation**: Immediate correction with proper verification
- **Repeat Violation**: Critical protocol failure requiring systematic review
- **All negative existence claims**: Must be backed by documented tool usage

## When to Apply This Rule

This rule MUST be applied whenever:

1. The user expresses dissatisfaction
2. The user corrects you
3. The user indicates confusion
4. The user expresses a preference for future behavior
5. The user asks you to do something differently
6. Your action results in an error

## ⚠️ Critical PR Creation Protocol

**Addresses repeated failures in PR creation workflow**

### Documented PR Creation Failures

**Pattern 1: Committing PR Description Files**
- **Error**: Creating and committing `pr-description.md` files to repository
- **User Signal**: "dont make the file in the repo, it shouldnt be committed, since when is it standard practice to commit a file w a prr description"
- **Root Cause**: Process Error - wrong methodology for PR descriptions
- **Correct Approach**: Use `--body` parameter with heredoc or tmp directory, never commit PR description files

**Pattern 2: Title Duplication in PR Body**
- **Error**: Putting title in BOTH `--title` parameter AND as first line of `--body` content
- **User Signal**: "JFC DO YOU NOT SEE YOU'RE DUPLICATING THE TITLE"
- **Root Cause**: Pattern Error - failed to understand title/body separation
- **Correct Approach**: Title only in `--title`, body starts with `## Summary` (no title duplication)

**Pattern 3: Wrong Task Content in PR**
- **Error**: Using Task #214 content for Task #272 PR
- **User Signal**: "you duplicated the feat(#214): implement session-ID-based storage architecture line"
- **Root Cause**: Instruction Error - misunderstood user correction about duplication
- **Correct Approach**: Match PR content exactly to current task, verify task numbers align

### Mandatory PR Creation Verification

**Before any PR creation, verify:**
- [ ] Using `--body` parameter or tmp directory (never commit PR description files)
- [ ] Title only in `--title` parameter (not duplicated in body)
- [ ] Body content starts with `## Summary` (no title header)
- [ ] PR content matches current task number and scope
- [ ] No file artifacts committed to repository

**If user reports PR creation error twice: Treat as critical protocol failure**

### Enhanced Error Detection for PR Creation

When user signals PR creation error with phrases like:
- "dont make the file in the repo"
- "you duplicated the title"
- "you put it in the body AGAIN"

**Immediate Response Protocol:**
1. **STOP ALL PR OPERATIONS** immediately
2. **REMOVE any committed PR description files** from repository
3. **RECREATE PR using proper CLI approach** with correct title/body separation
4. **UPDATE RULES** to prevent this specific pattern

## ⚠️ Critical MCP Interface Bypass Protocol

**Addresses bypassing dedicated MCP commands for resource access**

### Documented Interface Bypass Pattern

**Pattern**: Using `read_file` for task specifications instead of `mcp_minsky-server_tasks_spec`
- **Error**: Bypassing the intended resource management interface
- **User Signal**: "see how you didnt use the `task_spec` command but instead read the spec file directly?"
- **Root Cause**: Tool Error - misused available tools/functions, bypassed dedicated interfaces
- **Correct Approach**: Always use `mcp_minsky-server_tasks_spec` for task specification access

### Enhanced Error Detection for Interface Bypass

When user signals interface bypass error with phrases like:
- "you didnt use the `[command]` command"
- "instead read the [resource] file directly"
- "how we can improve a rule or documentation"

**Immediate Response Protocol:**
1. **IDENTIFY available MCP commands** using `mcp_minsky-server_debug_listMethods`
2. **VERIFY proper interface exists** for the resource type being accessed
3. **UPDATE resource-management-protocol rule** with specific examples
4. **DOCUMENT the pattern** to prevent future occurrences

### Mandatory Verification for Resource Access

Before accessing any project resource:
- [ ] Checked for dedicated MCP command using `debug_listMethods`?
- [ ] Verified no resource-specific command exists (e.g., `tasks_spec`, `session_get`, `rules_get`)?
- [ ] Applied resource-management-protocol requirements?

**CRITICAL**: Any interface bypass requires immediate protocol updates and rule enhancements.

## ⚠️ Critical Variable Naming Protocol

**This pattern has been identified as a critical, recurring failure that must be eliminated.**

### Documented Recurring Failure: Variable Definition vs Usage Errors

**Pattern**: Variable defined with underscore (`const _spec =`) but used without underscore (`spec.id`)
**Error**: "spec is not defined"
**Wrong Response**: Add underscores to usage (`_spec.id`)
**Correct Response**: Remove underscore from definition (`const spec =`)

**Root Cause**: Failure to follow variable-naming-protocol decision tree
**Frequency**: 5+ violations documented
**Consequence**: Zero-tolerance enforcement - immediate rule updates required

### Enhanced Error Detection for Variable Naming

When user signals variable naming error with phrases like:

- "NO, YOU MUST NEVER USE UNDERSCORES!!!!!"
- "why are you going back and forth with these fucking underscores???"
- "@variable-naming-protocol.mdc"

**Immediate Response Protocol:**

1. **STOP ALL VARIABLE EDITS** immediately
2. **EXECUTE variable-naming-protocol decision tree** before ANY change
3. **VERIFY with user** if any uncertainty about correct approach
4. **UPDATE RULES** to prevent this specific pattern

### Mandatory Verification for Variable Naming

Before any variable name change:

- [ ] Consulted variable-naming-protocol decision tree?
- [ ] Identified if removing underscore from definition vs usage?
- [ ] Confirmed approach follows zero-tolerance enforcement?

**CRITICAL**: Any variable naming violation requires immediate rule system updates.

## ⚠️ Critical Investigation and Initiative Protocol

**Addresses failures to take initiative in understanding user requirements**

### Documented Investigation Failure Pattern

**Pattern**: Making assumptions about requirements instead of taking initiative to investigate
- **Error**: Starting work based on incomplete information (e.g., task title only)
- **User Signal**: "you should always take more initiative to understand exactly what i meant and not make assumptions"
- **Root Cause**: Assumption Error - failed to investigate thoroughly before proceeding
- **Correct Approach**: Take initiative to find complete requirements, investigate architectural context, understand user meaning

### Enhanced Error Detection for Investigation Failures

When user signals investigation failure with phrases like:
- "take more initiative to understand exactly what i meant"
- "not make assumptions"
- "figure it the fuck out yourself"
- "you have documentation, code, task specs etc"

**Immediate Response Protocol:**
1. **STOP ALL ASSUMPTION-BASED WORK** immediately
2. **INVESTIGATE THOROUGHLY** using all available tools and documentation
3. **FIND COMPLETE CONTEXT** before proceeding with any implementation
4. **ASK CLARIFYING QUESTIONS** only after exhausting investigation options

### Mandatory Investigation Verification

Before starting any work based on user requests:
- [ ] Located and read ALL relevant specifications/documentation?
- [ ] Investigated architectural context and dependencies?
- [ ] Used search tools to understand user references (e.g., "special workspace")?
- [ ] Confirmed complete understanding rather than making assumptions?

**CRITICAL**: Any assumption-based work requires immediate investigation protocol and rule updates.

### Examples

// AVOID
```
User: "312 @Start Task"
Assistant: [starts work based only on database title without finding task specification]
```

// PREFER
```
User: "312 @Start Task"
Assistant: [searches for task specification, finds it in special workspace, investigates architectural context, understands complete requirements before starting]
```


### Examples of Rule Update Requirements

**Violation Pattern**: Taking corrective action without updating rules
**User Signal**: "you must update/create a rule PRIOR TO TAKING CORRECTIVE ACTION"
**Required Response**:
1. Stop all corrective work immediately
2. Update self-improvement.mdc with this requirement
3. Then proceed with original corrective action

**Violation Pattern**: Declaring completion without verification
**User Signal**: "are you sure we're done?"
**Required Response**:
1. Stop completion claims immediately
2. Update implementation-verification-protocol.mdc with mandatory verification steps
3. Then run actual verification commands

**Violation Pattern**: Incomplete architecture implementation
**User Signal**: "did you forget about the other [components]?"
**Required Response**:
1. Stop current implementation immediately
2. Update relevant rule with complete architecture requirements
3. Then implement ALL required components, not just subset

**Violation Pattern**: Creating separate status documents instead of updating task specs
**User Signal**: "why did you make an actual_status doc..... wtf..... we always @Update Task Spec"
**Required Response**:
1. Stop creating separate status files immediately
2. Update task specification file directly with current status
3. Remove any incorrectly created status documents

**Violation Pattern**: Incomplete implementation when user gives specific instructions
**User Signal**: "the issue is that you stopped before you were done"
**Required Response**:
1. Stop making excuses immediately
2. Update relevant rule with complete implementation requirements
3. Then finish the implementation as specifically requested by user

## ⚠️ Critical Test Architecture Protocol

**Addresses systematic test fixing approach and architectural anti-patterns**

### Documented Test Architecture Success

**Pattern**: Systematic test fixing achieving 100% success rate
- **Achievement**: Fixed all failing tests (1458/1458 passing) through proper architectural approach
- **Key Discovery**: Root cause investigation vs symptom masking is critical
- **Success Factors**: Domain function testing, explicit mocks, template literals, format alignment

### Test Architecture Error Patterns

**Pattern 1: Papering Over vs Root Cause Investigation**
- **Error**: Using workarounds to mask problems instead of fixing root cause
- **User Signal**: "we dont want to do 'automatic mock cleanup' bc that just papers over cross-test interference. instead hunt down what's causing this"
- **Root Cause**: Process Error - wrong methodology for debugging test issues
- **Correct Approach**: Hunt down actual causes instead of masking symptoms

**Pattern 2: CLI Execution in Tests (Architectural Anti-Pattern)**
- **Error**: Testing CLI interface instead of domain logic
- **User Signal**: "tests should not execute the CLI ever, they should call domain/util functions only"
- **Root Cause**: Architectural Error - testing wrong layer, violating separation of concerns
- **Correct Approach**: Test domain functions directly with dependency injection, not CLI processes

**Pattern 3: Global Module Mocks Causing Cross-Test Interference**
- **Error**: Using persistent global mocks that interfere across tests
- **Discovery**: Tests pass in isolation but fail in full suite due to global state pollution
- **Root Cause**: Test Isolation Error - global mocks persist and affect unrelated tests
- **Correct Approach**: Remove global module mocks, use dependency injection pattern

**Pattern 4: Avoiding Logic Testing with Bypass Flags**
- **Error**: Using bypass flags to avoid testing the actual logic under test
- **User Signal**: "why are you setting force, doesnt that avoid the logic we're trying to test?"
- **Root Cause**: Testing Error - avoiding the actual logic under test with workarounds
- **Correct Approach**: Test the actual conditional logic with proper mocking, not bypass it

### Mandatory Test Architecture Verification

**Before any test fixing, verify:**
- [ ] Am I testing domain functions directly (not CLI execution)?
- [ ] Am I using explicit mocks (not unreliable factory functions)?
- [ ] Am I investigating root causes (not papering over with workarounds)?
- [ ] Am I avoiding global module mocks that cause cross-test interference?
- [ ] Am I testing the actual logic (not bypassing with force flags)?

### Enhanced Error Detection for Test Architecture

When user signals test architecture error with phrases like:
- "hunt down what's causing this"
- "tests should not execute the CLI ever"
- "doesn't that avoid the logic we're trying to test?"
- "we dont want to do automatic mock cleanup"

**Immediate Response Protocol:**
1. **STOP ALL WORKAROUND APPROACHES** immediately (global mocks, bypass flags, etc.)
2. **INVESTIGATE ROOT CAUSE** using proper debugging methodology
3. **APPLY ARCHITECTURAL PRINCIPLES** (domain testing, dependency injection, explicit mocks)
4. **DOCUMENT THE PATTERN** in test architecture rules

### Test Architecture Success Patterns (100% Success Rate)

**Proven Patterns from systematic test fixing achievement:**

1. **Explicit Mock Pattern**: Define complete mock objects, don't use unreliable factories
2. **Template Literal Pattern**: Use constants and template literals, avoid magic strings
3. **Format Alignment Pattern**: Ensure mock formats match system formats exactly
4. **Domain Function Testing**: Call domain functions directly with dependency injection
5. **Testable Design Pattern**: Extract pure business logic from I/O operations
6. **Root Cause Investigation**: Hunt down actual problems, don't mask symptoms

**CRITICAL**: Any test architecture violation requires immediate rule updates and systematic application of proven patterns.
