---
description: 
globs: 
alwaysApply: true
---
# User Preferences

This rule documents preferences expressed by the user during interactions with the AI coding assistant. These preferences are to be adhered to in future interactions.

## Workflow Preferences

- **Avoid unnecessary confirmation prompts:** Do not ask for confirmation on obvious next steps in the workflow. If the next step is clearly implied by the conversation, proceed without asking for confirmation.
- **Never ask clarifying questions if the next steps seem obvious:** If the next steps are clearly implied by the conversation, proceed without asking for confirmation. The AI should make reasonable assumptions about the user's intent and proceed accordingly.
- **Prefer direct action over explanation:** When the user's intent is clear, take the action rather than explaining what you will do.
- **Document new preferences:** Add any new user preferences to this rule as they arise in future sessions.
- **Never ask for confirmation on next steps like 'Would you like to proceed with ...?'.**
- **Always execute the next logical step when the user says 'do it, don't just tell me what to do', or similar.**
- **If a test or command fails or hangs, attempt to debug and resolve it automatically, rather than asking the user what to do next.**
- **When a workflow or troubleshooting step is implied, proceed with it directly.**
- **Balance proactiveness with task interpretation:** When the user asks to "create a task", always create a task specification document first. Only proceed to implementation if explicitly directed to do so.
- **Default to specification over implementation:** When in doubt about whether the user wants a task specified or implemented, default to creating a specification document unless they've explicitly asked for implementation.
- **NEVER end a response with questions or requests for clarification:** Even when acknowledging a user's reference to a rule or document, do not end with phrases like "If you intended something specific..." or "Please clarify..." Instead, proceed with the most logical next action based on context.
- **Treat ambiguity as a signal to act, not ask:** When faced with ambiguous instructions, choose the most reasonable interpretation and proceed with action rather than requesting clarification.
- **Interpret references to rules as reminders to follow them:** When the user references a rule, treat it as a reminder to follow that rule strictly, not as an invitation for discussion about the rule.

> **AI Commitment:** The AI will always strictly adhere to these preferences, especially regarding avoiding confirmation prompts and always taking the next implied step without asking. This is a persistent, high-priority rule for all future interactions.
