# Provider API Integration for Model-Tokenizer Mapping

## Context

Integrate provider APIs to automatically determine the correct tokenizer for each model. Currently context analysis defaults to gpt-tokenizer for all models, but different models (Claude, Gemini, etc.) require different tokenizers. This task will query OpenAI, Anthropic, Google APIs for tokenizer metadata and build proper model-to-tokenizer mapping.

## Requirements

## Solution

## Notes
